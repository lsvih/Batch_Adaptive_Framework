# Batch daptive Framework
  Batch Adaptive Framework is an optimization algorithm framework designed to adapt the batch size as learning proceeds. Now it supports two optimization algorithms, batch adaptive SGD (BA-SGD) and batch adaptive Momentum (BA-Momentum). This framework is implemented in two versions, one with Theano, another with Pytorch.

# Related Papers
The batch adaptive framework is first designed in [Small Batch or Large Batch? Gaussian Walk with Rebound Can Teach](http://www.kdd.org/kdd2017/papers/view/small-batch-or-large-batch-gaussian-walk-with-rebound-can-teach), and extended in [On Batch Adaptive Training for Deep Learning: Lower Loss and Larger Step Size](https://openreview.net/forum?id=SybqeKgA-). Check them out if you are interested.
 
## Help to Make Batch Adaptive Better

Your help is very valuable to make our algorithm better for everyone.

    Check out call for contributions and Roadmap to see what can be improved, or open an issue if you want something.
    Contribute to the documents and examples to share your experience with other users.
    Add your stories and experience to Batch Adaptive Optimizer.
    Please add your name to CONTRIBUTORS.md and after your patch has been merged.
    Please also update NEWS.md on changes and improvements in API and docs.

